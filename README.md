# Ethics Reading List

[![PRs Welcome](assets/img/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

A list of ethics related resources for researchers and practitioners of Natural Language Processing and Computational Linguistics.  This is a public list moderated by the current ACL Ethics Committee.  Please issue a pull request against the repository to have your suggestions discussed before they are approved for integration with the list.  Thanks!

This list is intentionally kept with simple formatting in Markdown to allow machine-readable processing of the resource.

_Last Updated: 2021 Oct 12_

### Guidelines
* Add your name to the [contributors](#contributors) section as part of your PR.  Include an affiliation and a weblink if you'd like.
* References follow a three tier organization: by topic, then by year, then by first-author surname.
* Use APA style where possible.
* Add minimally a `paper` link to direct readers directly to the `.pdf` or metadata page (arXiv or ACL Anthology) of the paper.

### Contributed by
* [KarÃ«n Fort](https://members.loria.fr/KFort/) (Sorbonne UniversitÃ©)

# Contents
* [General Resources](#general-resources)
* [Evaluation](#evaluation)
* [Model Issues](#model-issues)
* [Biases](#biases)
* [Language Variation](#language-variation)
* [Dual-Use](#dual-use)
* [Environmental Impact](#environmental-impact)
* [Data](#data)
* [Crowdsourcing Issues](#crowdsourcing-issues)
* [Uncategorized](#uncategorized)

### General Resources

#### 2020â€“2021

* Aka, O., Burke, K., BÃ¤uerle, A., Greer, C., & Mitchell, M. (2021). Measuring Model Biases in the Absence of Ground Truth. arXiv preprint arXiv:2103.03417. [[paper](https://arxiv.org/abs/2103.03417)]

* Schwartz, R., Dodge, J., Smith, N. A., & Etzioni, O. (2020). Green AI. Communications of the ACM, 63(12), 54-63. [[paper](http://arxiv.org/abs/1907.10597)]

#### 2010â€“2019

* Monteiro, M. (2019). Ruined by design: How designers destroyed the world, and what we can do to fix it. Mule Design.

* Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., DaumÃ© III, H., & Crawford, K. (2018). Datasheets for datasets. arXiv preprint arXiv:1803.09010. [[paper](http://arxiv.org/abs/1803.09010)]

* Amblard, M. (2016). Pour un TAL responsable. Traitement Automatique des Langues, 57(2), 21-45. [[paper](https://hal.inria.fr/hal-01414145)]

* Fort, K., & Couillault, A. (2016, May). Yes, we care! results of the ethics and natural language processing surveys. In international Language Resources and Evaluation Conference (LREC) 2016. [[paper](https://hal.inria.fr/hal-01287467/file/EthicsAndNLPSurveys.pdf)]

* Hovy, D., & Spruit, S. L. (2016, August). The social impact of natural language processing. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 591-598) doi:10.18653/v1/P16-2096. [[paper](https://www.aclweb.org/anthology/P16-2096)]

* Lefeuvre-Halftermeyer, A., Govaere, V., Antoine, J. Y., Allegre, W., Pouplin, S., Departe, J. P., ... & Spagnulo, A. (2016). Typologie des risques pour une analyse Ã©thique de l'impact des technologies du TAL. Traitement Automatique des Langues, 57(2), 47-71.
[[paper](https://hal.archives-ouvertes.fr/hal-01501192)]

* Ferraro, F., Mostafazadeh, N., Vanderwende, L., Devlin, J., Galley, M., & Mitchell, M. (2015). A survey of current datasets for vision and language research. arXiv preprint arXiv:1506.06833. doi:10.18653/v1/D15-1021
[[paper](https://www.aclweb.org/anthology/D15-1021)]

### Evaluation

#### 2020â€“2021

* Tan, S., Joty, S., Baxter, K., Taeihagh, A., Bennett, G. A., & Kan, M. Y. (2021). Reliability Testing for Natural Language Processing Systems. arXiv preprint arXiv:2105.02590.
doi:10.18653/v1/2021.acl-long.321
[[paper](https://aclanthology.org/2021.acl-long.321/)

* Caglayan, O., Madhyastha, P., & Specia, L. (2020). Curious case of language generation evaluation metrics: A cautionary tale. arXiv preprint arXiv:2010.13588. doi:10.18653/v1/2020.coling-main.210
[[paper](https://www.aclweb.org/anthology/2020.coling-main.210)]

* Ethayarajh, K., & Jurafsky, D. (2020). Utility is in the eye of the user: A critique of NLP leaderboards. arXiv preprint arXiv:2009.13888. doi:10.18653/v1/2020.emnlp-main.393
[[paper](https://www.aclweb.org/anthology/2020.emnlp-main.393)]

* Garnerin, M., Rossato, S., & Besacier, L. (2020). Pratiques dâ€™Ã©valuation en ASR et biais de performance (Evaluation methodology in ASR and performance bias). In Actes de la 6e confÃ©rence conjointe JournÃ©es d'Ã‰tudes sur la Parole (JEP, 33e Ã©dition), Traitement Automatique des Langues Naturelles (TALN, 27e Ã©dition), Rencontre des Ã‰tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RÃ‰CITAL, 22e Ã©dition). 2e atelier Ã‰thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 1-9). [[paper](https://www.aclweb.org/anthology/2020.jeptalnrecital-eternal.1)]

* Goldfarb-Tarrant, S., Marchant, R., Sanchez, R. M., Pandya, M., & Lopez, A. (2020). Intrinsic bias metrics do not correlate with application bias. arXiv preprint arXiv:2012.15859.

* Linzen, T. (2020). How can we accelerate progress towards human-like linguistic generalization?. arXiv preprint arXiv:2005.00955. doi:10.18653/v1/2020.acl-main.465 [[paper](https://www.aclweb.org/anthology/2020.acl-main.465)]

* Mathur, N., Baldwin, T., & Cohn, T. (2020). Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics. arXiv preprint arXiv:2006.06264. doi:10.18653/v1/2020.acl-main.448
[[paper](https://www.aclweb.org/anthology/2020.acl-main.448)]

* Nangia, N., Vania, C., Bhalerao, R., & Bowman, S. R. (2020). CrowS-pairs: A challenge dataset for measuring social biases in masked language models. arXiv preprint arXiv:2010.00133. doi:10.18653/v1/2020.emnlp-main.154 [[paper](https://www.aclweb.org/anthology/2020.emnlp-main.154)]

#### 2010â€“2019

* Bregeon, D., Antoine, J. Y., Villaneau, J., & Lefeuvre-Halftermeyer, A. (2019). Redonner du sens Ã  lâ€™accord interannotateurs: vers une interprÃ©tation des mesures dâ€™accord en termes de reproductibilitÃ© de lâ€™annotation. Traitement Automatique des Langues, 60(2), 23.  [[paper](https://hal.archives-ouvertes.fr/hal-02375240)]

* Caliskan, A., Bryson, J. J., & Narayanan, A. (2017). Semantics derived automatically from language corpora contain human-like biases. Science, 356(6334), 183-186.

* Mathet, Y., & WidlÃ¶cher, A. (2016). Ã‰valuation des annotations: ses principes et ses piÃ¨ges. Traitement Automatique des Langues, 57(2), 73-98. [[paper](https://hal.archives-ouvertes.fr/hal-01712282)]

### Model Issues

#### 2020â€“2021

* Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021, March). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?ðŸ¦œ. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (pp. 610-623). doi:10.1145/3442188.3445922 [[paper](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)]

### Biases

#### 2020â€“2021

* Blodgett, S. L., Barocas, S., DaumÃ© III, H., & Wallach, H. (2020). Language (technology) is power: A critical survey of" bias" in NLP. arXiv preprint arXiv:2005.14050. doi:10.18653/v1/2020.acl-main.485
[[paper](https://www.aclweb.org/anthology/2020.acl-main.485)]

* Mohammad, S. M. (2020). Gender gap in natural language processing research: Disparities in authorship and citations. arXiv preprint arXiv:2005.00962. doi:10.18653/v1/2020.acl-main.702 [[paper](https://www.aclweb.org/anthology/2020.acl-main.702)]

* Nissim, M., van Noord, R., & van der Goot, R. (2020). Fair is better than sensational: Man is to doctor as woman is to doctor. Computational Linguistics, 46(2), 487-497. doi:10.1162/coli\_a\_00379 [[paper](https://www.aclweb.org/anthology/2020.cl-2.7)]

* Schluter, N. (2018). The glass ceiling in NLP. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing (pp. 2793-2798). doi:10.18653/v1/D18-1301
[[paper](https://www.aclweb.org/anthology/D18-1301)]

* Fort, K., & NÃ©vÃ©ol, A. (2018, January). PrÃ©sence et reprÃ©sentation des femmes dans le traitement automatique des langues en France. In Penser la Recherche en Informatique comme pouvant Ãªtre SituÃ©e, Multidisciplinaire Et GenrÃ©e (PRISME-G).
[[paper](https://hal.archives-ouvertes.fr/hal-01683774)]

### Language Variation

#### 2020â€“2021
* Markl, N., & Lai, C. (2021, April). Context-sensitive evaluation of automatic speech recognition: considering user experience & language variation. In Proceedings of the First Workshop on Bridging Humanâ€“Computer Interaction and Natural Language Processing (pp. 34-40). [[paper](https://www.aclweb.org/anthology/2021.hcinlp-1.6.pdf)]

* Joshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. arXiv preprint arXiv:2004.09095. [[paper](https://arxiv.org/pdf/2004.09095)]

* Koenecke, A., Nam, A., Lake, E., Nudell, J., Quartey, M., Mengesha, Z., ... & Goel, S. (2020). Racial disparities in automated speech recognition. Proceedings of the National Academy of Sciences, 117(14), 7684-7689. [[paper](https://www.pnas.org/content/117/14/7684?utm_keyword=referral_input)]

#### 2010â€“2019

* Bender, E. M. (2019). The #benderrule: On naming the languages we study and why it matters. The Gradient, 14. [[paper](http://faculty.washington.edu/ebender/papers/BenderRule_TheGradient-refs.pdf)]

* Garimella, A., Banea, C., Hovy, D., & Mihalcea, R. (2019, July). Womenâ€™s syntactic resilience and menâ€™s grammatical luck: Gender-Bias in Part-of-Speech Tagging and Dependency Parsing. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (pp. 3493-3498). [[paper](https://aclanthology.org/P19-1339.pdf)]

* Huang, X., & Paul, M. (2019, June). Neural user factor adaptation for text classification: Learning to generalize across author demographics. In Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (* SEM 2019) (pp. 136-146). [[paper](https://aclanthology.org/S19-1015.pdf)]

* Zmigrod, R., Mielke, S. J., Wallach, H., & Cotterell, R. (2019). Counterfactual data augmentation for mitigating gender stereotypes in languages with rich morphology. arXiv preprint arXiv:1906.04571. [[paper](https://aclanthology.org/P19-1161.pdf)]

* Broussard, M. (2018). Why the Scots are such a struggle for Alexa and Siri. The Herald,(Glasgow, UK), May, 11. [[paper]()]

* Jurgens, D., Tsvetkov, Y., & Jurafsky, D. (2017, July). Incorporating dialectal variability for socially equitable language identification. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) (pp. 51-57). [[paper](https://www.aclweb.org/anthology/P17-2009.pdf)]

* Tatman, R. (2017, April). Gender and dialect bias in YouTubeâ€™s automatic captions. In Proceedings of the First ACL Workshop on Ethics in Natural Language Processing (pp. 53-59). [[paper](https://www.aclweb.org/anthology/W17-1606.pdf)]

* JÃ¸rgensen, A., Hovy, D., & SÃ¸gaard, A. (2015, July). Challenges of studying and processing dialects in social media. In Proceedings of the workshop on noisy user-generated text (pp. 9-18). [[paper](https://www.aclweb.org/anthology/W15-4302.pdf)]

* Hovy, D., & SÃ¸gaard, A. (2015, July). Tagging performance correlates with author age. In Proceedings of the 53rd annual meeting of the Association for Computational Linguistics and the 7th international joint conference on natural language processing (volume 2: Short papers) (pp. 483-488). [[paper](https://www.aclweb.org/anthology/P15-2079.pdf)]

### Dual Use


#### 2020â€“2021

* Bonastre, J. F. (2020). 1990-2020: retours sur 30 ans dâ€™Ã©changes autour de lâ€™identification de voix en milieu judiciaire. In 6e confÃ©rence conjointe JournÃ©es d'Ã‰tudes sur la Parole (JEP, 33e Ã©dition), Traitement Automatique des Langues Naturelles (TALN, 27e Ã©dition), Rencontre des Ã‰tudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RÃ‰CITAL, 22e Ã©dition). 2e atelier Ã‰thique et TRaitemeNt Automatique des Langues (ETeRNAL) (pp. 38-47). ATALA; AFCP.

### Environmental Impact

#### 2020â€“2021

* Lannelongue, L., Grealey, J., & Inouye, M. (2021). Green algorithms: Quantifying the carbon footprint of computation. Advanced Science, 2100707. doi:10.1002/advs.202100707
[[paper](https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202100707)]

* Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., & Pineau, J. (2020). Towards the systematic reporting of the energy and carbon footprints of machine learning. Journal of Machine Learning Research, 21(248), 1-43. [[paper](https://www.jmlr.org/papers/volume21/20-312/20-312.pdf)]

* Anthony, L. F. W., Kanding, B., & Selvan, R. (2020). Carbontracker: Tracking and predicting the carbon footprint of training deep learning models. arXiv preprint arXiv:2007.03051. [[paper](https://arxiv.org/pdf/2007.03051)]

#### 2010â€“2019

* Strubell, E., Ganesh, A., & McCallum, A. (2019). Energy and policy considerations for deep learning in NLP. arXiv preprint arXiv:1906.02243. doi:10.18653/v1/P19-1355
[[paper](https://www.aclweb.org/anthology/P19-1355)]

### Data

#### 2020â€“2021

* Bird, S. (2020, December). Decolonising speech and language technology. In Proceedings of the 28th International Conference on Computational Linguistics (pp. 3504-3519). doi:10.18653/v1/2020.coling-main.313
[[paper](https://www.aclweb.org/anthology/2020.coling-main.313)]

* Joshi, P., Santy, S., Budhiraja, A., Bali, K., & Choudhury, M. (2020). The state and fate of linguistic diversity and inclusion in the NLP world. arXiv preprint arXiv:2004.09095.
doi:10.18653/v1/2020.acl-main.560
[[paper](https://www.aclweb.org/anthology/2020.acl-main.560)]

* Vidgen, B., & Derczynski, L. (2020). Directions in abusive language training data, a systematic review: Garbage in, garbage out. PloS one, 15(12), e0243300.
[[paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0243300)]

* Paullada, A., Raji, I. D., Bender, E. M., Denton, E., & Hanna, A. (2020). Data and its (dis) contents: A survey of dataset development and use in machine learning research. arXiv preprint arXiv:2012.05345. [[paper](https://arxiv.org/pdf/2012.05345)]

#### 2010â€“2019

* Kann, K., Cho, K., & Bowman, S. R. (2019). Towards realistic practices in low-resource natural language processing: the development set. arXiv preprint arXiv:1909.01522.
doi:10.18653/v1/D19-1329 [[paper](https://www.aclweb.org/anthology/D19-1329)]

* Bender, E. M., & Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6, 587-604 doi:10.1162/tacl\_a\_00041 [[paper](https://www.aclweb.org/anthology/Q18-1041)]

* Couillault, A., Fort, K., Adda, G., & De Mazancourt, H. (2014, May). Evaluating corpora documentation with regards to the ethics and big data charter. In International Conference on Language Resources and Evaluation (LREC). [[paper](https://hal.inria.fr/hal-00969180)]

### Crowdsourcing Issues

#### 2020â€“2021

* Caswell, I., Kreutzer, J., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., ... & Adeyemi, M. (2021). Quality at a glance: An audit of web-crawled multilingual datasets. arXiv preprint arXiv:2103.12028. [[paper](https://arxiv.org/pdf/2103.12028)]

* Shmueli, B., Fell, J., Ray, S., & Ku, L. W. (2021). Beyond fair pay: Ethical implications of NLP crowdsourcing. arXiv preprint arXiv:2104.10097. [[paper](https://arxiv.org/pdf/2104.10097)]

#### 2010â€“2019

* Callison-Burch, C. (2014, September). Crowd-workers: Aggregating information across turkers to help them find higher paying work. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 2, No. 1). [[paper](https://ojs.aaai.org/index.php/HCOMP/article/download/13198/13046)]

* Bederson, B. B., & Quinn, A. J. (2011). Web workers unite! addressing challenges of online laborers. In CHI'11 Extended Abstracts on Human Factors in Computing Systems (pp. 97-106).

* Fort, K., Adda, G., & Cohen, K. B. (2011). Amazon Mechanical Turk: Gold mine or coal mine?. Computational Linguistics, 37(2), 413-420. doi:10.1162/COLI\_a\_00057 [[paper](https://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00057)]

* Snyder, J. (2010). Exploitation and sweatshop labor: Perspectives and issues. Business Ethics Quarterly, 20(2), 187-213.
[[paper](https://crowdsourcing-class.org/readings/downloads/ethics/exploitation-and-sweatshop-labor.pdf)]

### Uncategorized

* Schneider, J. M., Rehm, G., Montiel-Ponsoda, E., Doncel, V. R., Revenko, A., Karampatakis, S., ... & Maganza, F. (2020, May). Orchestrating NLP Services for the Legal Domain. In Proceedings of the 12th Language Resources and Evaluation Conference (pp. 2332-2340). [[paper](https://aclanthology.org/2020.lrec-1.284)]

* Sap, M., Gabriel, S., Qin, L., Jurafsky, D., Smith, N. A., & Choi, Y. (2019). Social bias frames: Reasoning about social and power implications of language. arXiv preprint arXiv:1911.03891. [[paper](http://arxiv.org/abs/1911.03891)]
